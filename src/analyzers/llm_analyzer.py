"""LLM-based tweet analyzer using OpenAI."""

from datetime import datetime
from loguru import logger
from openai import AsyncOpenAI

from src.models import Tweet, DailySummary


SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¤¾äº¤åª’ä½“åˆ†æå¸ˆï¼Œæ“…é•¿åˆ†ææ¨æ–‡å†…å®¹å¹¶æä¾›æ·±åº¦è§è§£ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. æ€»ç»“æ¯ä¸ªè´¦å·çš„ä¸»è¦åŠ¨æ€
2. è¯†åˆ«é‡è¦è¯é¢˜å’Œè¶‹åŠ¿
3. åˆ†æè§‚ç‚¹å’Œç«‹åœº
4. æä¾›æ·±åº¦è¯„è®ºå’Œæ´å¯Ÿ

è¯·ä½¿ç”¨ä¸­æ–‡å›å¤ï¼Œä¿æŒä¸“ä¸šã€å®¢è§‚çš„åˆ†æé£æ ¼ã€‚"""


class LLMAnalyzer:
    """Analyzer using OpenAI for tweet analysis."""

    def __init__(self, api_key: str, model: str = "gpt-4-turbo-preview"):
        """Initialize the analyzer."""
        self.client = AsyncOpenAI(api_key=api_key)
        self.model = model

    def _format_tweets_for_analysis(self, tweets: list[Tweet]) -> str:
        """Format tweets into a string for LLM analysis."""
        if not tweets:
            return "æ²¡æœ‰æ¨æ–‡æ•°æ®ã€‚"

        # Group by author
        by_author: dict[str, list[Tweet]] = {}
        for tweet in tweets:
            if tweet.author_username not in by_author:
                by_author[tweet.author_username] = []
            by_author[tweet.author_username].append(tweet)

        lines = []
        for author, author_tweets in by_author.items():
            display_name = author_tweets[0].author_display_name or author
            lines.append(f"\n## @{author} ({display_name})")
            lines.append(f"å…± {len(author_tweets)} æ¡æ¨æ–‡\n")

            for tweet in author_tweets[:10]:  # Limit per author
                time_str = tweet.created_at.strftime("%Y-%m-%d %H:%M")
                engagement = f"â¤ï¸{tweet.likes} ğŸ”{tweet.retweets} ğŸ’¬{tweet.replies}"

                prefix = ""
                if tweet.is_retweet:
                    prefix = "[è½¬æ¨] "
                elif tweet.is_reply:
                    prefix = "[å›å¤] "

                lines.append(f"- [{time_str}] {prefix}{tweet.content[:200]}")
                lines.append(f"  {engagement}")
                lines.append(f"  {tweet.url}\n")

        return "\n".join(lines)

    async def analyze_tweets(self, tweets: list[Tweet], date: datetime) -> DailySummary:
        """Analyze tweets and generate daily summary.

        Args:
            tweets: List of tweets to analyze
            date: The date being summarized

        Returns:
            DailySummary with LLM-generated content
        """
        date_str = date.strftime("%Yå¹´%mæœˆ%dæ—¥")
        formatted_tweets = self._format_tweets_for_analysis(tweets)

        # Get unique authors
        authors = set(t.author_username for t in tweets)

        user_prompt = f"""è¯·åˆ†æä»¥ä¸‹ {date_str} çš„æ¨æ–‡æ•°æ®ï¼Œå¹¶æä¾›ï¼š

1. **æ¯æ—¥æ‘˜è¦**ï¼šç®€è¦æ€»ç»“æ¯ä¸ªè´¦å·çš„ä¸»è¦åŠ¨æ€ï¼ˆ2-3å¥è¯/è´¦å·ï¼‰
2. **çƒ­ç‚¹è¯é¢˜**ï¼šè¯†åˆ«å‡ºç°çš„ä¸»è¦è¯é¢˜å’Œè¶‹åŠ¿
3. **æ·±åº¦åˆ†æ**ï¼šåˆ†æè¿™äº›æ¨æ–‡åæ˜ çš„è§‚ç‚¹ã€ç«‹åœºå’Œæ½œåœ¨å½±å“
4. **å…³é”®æ´å¯Ÿ**ï¼šåˆ—å‡º3-5æ¡æœ€é‡è¦çš„å‘ç°

æ¨æ–‡æ•°æ®ï¼š
{formatted_tweets}

è¯·ç”¨ç»“æ„åŒ–çš„æ ¼å¼è¾“å‡ºåˆ†æç»“æœã€‚"""

        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=0.7,
                max_tokens=4000,
            )

            analysis_text = response.choices[0].message.content or ""
            logger.info(f"Generated analysis for {len(tweets)} tweets")

            # Extract key insights (simple extraction)
            key_insights = []
            if "å…³é”®æ´å¯Ÿ" in analysis_text or "å…³é”®å‘ç°" in analysis_text:
                lines = analysis_text.split("\n")
                in_insights = False
                for line in lines:
                    if "å…³é”®æ´å¯Ÿ" in line or "å…³é”®å‘ç°" in line:
                        in_insights = True
                        continue
                    if in_insights and line.strip().startswith(("-", "â€¢", "1", "2", "3", "4", "5")):
                        insight = line.strip().lstrip("-â€¢0123456789. ")
                        if insight:
                            key_insights.append(insight)
                    elif in_insights and line.strip() and not line.strip().startswith("#"):
                        if len(key_insights) >= 5:
                            break

            return DailySummary(
                date=date,
                accounts_monitored=len(authors),
                total_tweets=len(tweets),
                tweets=tweets,
                summary_text=analysis_text,
                analysis=analysis_text,
                key_insights=key_insights[:5],
            )

        except Exception as e:
            logger.error(f"Error analyzing tweets: {e}")
            return DailySummary(
                date=date,
                accounts_monitored=len(authors),
                total_tweets=len(tweets),
                tweets=tweets,
                summary_text=f"åˆ†æç”Ÿæˆå¤±è´¥: {e}",
                analysis="",
            )
